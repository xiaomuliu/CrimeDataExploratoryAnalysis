---
title: "BeatwiseTimeSeries"
date: "September 14, 2015"
output: html_document
---

```{r load-crimedata,echo=FALSE,message=FALSE,cache=TRUE}
setwd("/Users/xiaomuliu/CrimeProject/SpatioTemporalModeling/ExploratoryAnalysis/CrimeDataSTAnalysis2/")
source("importCrimeData.R")
filePath <- "/Users/xiaomuliu/CrimeProject/SpatioTemporalModeling/ExploratoryAnalysis/DataPortal/"
fileName <- "VIOLENTCRIME_01_14.csv"
CrimeData <- importCrimeData(filePath,fileName)
row.names(CrimeData) <- NULL
```

```{r load-shapefile,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
library(rgdal)
shapefilePath.new <- "/Users/xiaomuliu/CrimeProject/SpatioTemporalModeling/CPDShapeFiles/new/"
beat_new.rg <- readOGR(paste0(shapefilePath.new,"cpd_beats"), "cpd_beats")
district_new.rg <- readOGR(paste0(shapefilePath.new, "cpd_districts"),"cpd_districts")
# centroids 
Crd.beat <- coordinates(beat_new.rg)
Crd.district <- coordinates(district_new.rg)
```

The beat and district numbers in the data were re-assigned by finding in which new beat/district polygon the point falls and then label that beat/district number. Therefore all violent crime beat and district records have a unified reference which is the new CPD beat/district map.

```{r rearrange-data,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
library(rgeos)
## Match old and new beat 
# Matching the old beat records and the new one by finding which new beat polygon the point falls in
# and then re-assign that beat number to that crime record. 
# Therefore all crime beat records have a unified reference which is the new beat map.
source("DataPolyMatching.R")
# Match1 <- DataMatching2(CrimeData,beat_new.rg,area="BEAT")
# CrimeData <- Match1$CrimeData
# Match2 <- DataMatching2(CrimeData,district_new.rg,area="DISTRICT")
# CrimeData <- Match2$CrimeData
CrimeData <- DataMatching3(CrimeData,beat_new.rg,area="BEAT")
CrimeData <- DataMatching3(CrimeData,district_new.rg,area="DISTRICT")

## Aggregated by "beat" and add 'holiday' attribute
source("HolidayChart.R")
CrimeData.beat_day <- aggregate(INC_CNT~BEAT+DISTRICT+DATEOCC+YEAR+MONTH+DOW,data=CrimeData, FUN=sum, na.rm=TRUE)
CrimeData.beat_day <- CrimeData.beat_day[order(CrimeData.beat_day$DATEOCC),]
CrimeData.beat_day$DOW <- factor(CrimeData.beat_day$DOW, levels=c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"))
CrimeData.beat_day$HOLIDAY <- sapply(CrimeData.beat_day$DATEOCC,FUN=holidays)
CrimeData.beat_day$HOLIDAY <- factor(CrimeData.beat_day$HOLIDAY)

CrimeData$HOLIDAY <- sapply(CrimeData$DATEOCC,FUN=holidays)
CrimeData$HOLIDAY <- factor(CrimeData$HOLIDAY)
```

```{r construct-panel-data,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
## Create a full panel (of size "number of beats * number of dates") data frame and an corresponding STFDF
beat_template.spdf <- beat_new.rg
# remove some useless/redundant attributes
beat_template.spdf@data$SECTOR <- NULL
beat_template.spdf@data$BEAT <- NULL
beat_template.spdf@data$BEAT_NUM <- NULL
# add an attribute INC_CNT
beat_template.spdf@data$INC_CNT <- rep(NA,nrow(beat_template.spdf@data))

source("ConstructSTData.R")
STdata.beat <- ConstructArealSTData(CrimeData.beat_day,beat_template.spdf,Crd.beat,area="BEAT") 
CrimeData_beat_day.stfdf <-STdata.beat$CrimeData.stfdf 
CrimeData.beat_day <- STdata.beat$CrimeData 

# Add corresponding district numbers for each beat
inDistrict <- aggregate(.~BEAT_NUMBE,data=beat_template.spdf@data[,c("DISTRICT","BEAT_NUMBE")],FUN=function(x){x[1]})
names(inDistrict)[names(inDistrict)=="BEAT_NUMBE"] <- "BEAT"
inDistrict$DISTRICT <- factor(inDistrict$DISTRICT)
levels(inDistrict$DISTRICT) <- levels(CrimeData$DISTRICT)

CrimeData_beat_day.stfdf@data$DISTRICT <- rep(NA,nrow(CrimeData_beat_day.stfdf@data))
for (i in 1:nrow(inDistrict)){
  CrimeData.beat_day$DISTRICT[CrimeData.beat_day$BEAT==inDistrict$BEAT[i]] <- inDistrict$DISTRICT[i]
  CrimeData_beat_day.stfdf@data$DISTRICT[CrimeData_beat_day.stfdf@data$BEAT==inDistrict$BEAT[i]] <- inDistrict$DISTRICT[i]
}
```

```{r load-weather-data,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
## Load weather data
source("WeatherDataFunctions.R")
WeatherFilePath <- "/Users/xiaomuliu/CrimeProject/SpatioTemporalModeling/ExploratoryAnalysis/WeatherData/"
startDate="01/01/2001"
endDate="12/31/2014"
filename.daily <- paste(WeatherFilePath,'WeatherData_Daily_',as.character(as.Date(startDate, "%m/%d/%Y")),
                        '_',as.character(as.Date(endDate, "%m/%d/%Y")),'.csv',sep='')
WeatherData.daily <- read.csv(filename.daily)
WeatherData.daily$Date <- as.Date(WeatherData.daily$Date)
WeatherData.daily_diff <- DailyWeatherDiff(WeatherData.daily)
```

```{r fit-beat-trend,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
## Fit a temporal model which is specified below for every district
require(MASS)
require(glmnet)
require(dummies)
require(spacetime)
require(doMC)
registerDoMC(cores=4)

beatList <- sort(unique(CrimeData.beat_day$BEAT))
districtList <- sort(unique(CrimeData.beat_day$DISTRICT))
NumBeat <- length(beatList)
NumDistrict <- length(districtList)
district_NumBeat <- aggregate(BEAT~DISTRICT,data=CrimeData.beat_day,FUN=function(x){length(unique(x))})
names(district_NumBeat) <- c("DISTRICT","NumBeat")

# First 'trendLen' instances work as buffering data
trendLen <- 730
CrimeData.buffer <- CrimeData.beat_day[1:NumBeat*trendLen,]
CrimeData.nonbuffer <- CrimeData.beat_day[(NumBeat*trendLen+1):nrow(CrimeData.beat_day),]
CrimeData.nonbuffer$TStrend <- rep(NA,nrow(CrimeData.nonbuffer))
CrimeData.nonbuffer$TSdetrendRes <- rep(NA,nrow(CrimeData.nonbuffer))
WeatherData.nonbuffer <- WeatherData.daily[(trendLen+1):nrow(WeatherData.daily),]
WeatherDataDiff.nonbuffer <- WeatherData.daily_diff[(trendLen-1):nrow(WeatherData.daily_diff),] 

## Predict trend and get residuals for each district (beat)
source("TimeSeriesFunction.R")
for (i in beatList){
  CrimeData.beat <- subset(CrimeData.beat_day,BEAT==i,select=c("DATEOCC","DOW","MONTH","HOLIDAY","INC_CNT"))
  # Smooth out holiday cases:
  CrimeData.beat$INC_CNT_s <- SmoothHoliday(CrimeData.beat)
  
  Trend <- PredictTrend(CrimeData.beat,trendLen,nlfit="IRLS")
  CrimeData.nonbuffer$TStrend[CrimeData.nonbuffer$BEAT==i] <- Trend  
  CrimeData.nonbuffer$TSdetrendRes[CrimeData.nonbuffer$BEAT==i] <- CrimeData.nonbuffer$INC_CNT[CrimeData.nonbuffer$BEAT==i]-Trend
}
```
The evaluation date starts from 2014-01-01 and ends on 2014-12-31. The time series training uses preceding 12-year data (or windowed 12-year data) of the corresponding testing date. 
```{r TS-setting,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
library(raster)

glm <- "gaussian"
varSet <- c("DOW","weather","weatherdiff","timelag")
standardize <- "minmax"
Windowing <- TRUE
nlambda <- 15
parallel <- TRUE

startDate.eval = as.Date("2014-01-01")
endDate.eval <- as.Date("2014-12-31")
dateSeq.eval <- seq.Date(startDate.eval,endDate.eval,by=1)
Ntrain <- 365*12
winSize <- 90
winNum <- 12

CrimeData.eval <- subset(CrimeData.nonbuffer,DATEOCC %in% dateSeq.eval)
CrimeData.eval$TSresPred <- rep(NA,nrow(CrimeData.eval))

ncell.x <- 120
ncell.y <- 160
X_range <- beat_new.rg@bbox[1,]
Y_range <- beat_new.rg@bbox[2,]
grd.full <- expand.grid(list(X_COORD=seq(X_range[1],X_range[2],length.out=ncell.x),
                             Y_COORD=seq(Y_range[1],Y_range[2],length.out=ncell.y)))
coordinates(grd.full) = ~X_COORD+Y_COORD # convert to SpatialPoints
proj4string(grd.full) <- proj4string(beat_new.rg)

grdInPoly <- over(grd.full,as(beat_new.rg,"SpatialPolygons"))

grd.beat_s <- grd.full[!is.na(grdInPoly)]
grd.beat_s <- SpatialPixels(grd.beat_s)
```

```{r TS,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
for (i in 1:length(dateSeq.eval)){  
  # pinpoint the training time range
  d <- dateSeq.eval[i]
  startDate.train <- d-Ntrain
  endDate.train <- d-1
  dateSeq.train <- seq.Date(startDate.train,endDate.train,by=1)
  
  if (Windowing){
    dateWindow <- HistDateWindows(dateSeq.train,d,windowSize=winSize,windowNum=winNum,interval=365.25,dir="backward")
  }
  
  for (j in beatList){
    # beat 3100 has too few samples
    if (j=="3100"){
      CrimeData.eval$TSresPred[CrimeData.eval$BEAT==j&CrimeData.eval$DATEOCC==d] <- 0
      next
    }
    
    #Combine training data of all variables 
    CrimeData.nonbuffer_beat<- subset(CrimeData.nonbuffer,BEAT==j,
                                      select=c("DATEOCC","DOW","MONTH","INC_CNT","TStrend","TSdetrendRes"))
    selectData <- VariableSet(varSet,CrimeData.nonbuffer_beat,WeatherData.nonbuffer,WeatherDataDiff.nonbuffer,glm)
    X <- selectData$X
    y <- selectData$y
    CrimeData.nonbuffer_beat2 <- selectData$crimeData
    
    if (Windowing){
      idx.tr <- CrimeData.nonbuffer_beat2$DATEOCC %in% dateWindow$histDates
    }
    else{
      idx.tr <- CrimeData.nonbuffer_beat2$DATEOCC %in% dateSeq.train
    }
    
    idx.te <- CrimeData.nonbuffer_beat2$DATEOCC %in% d 
    X.train_raw <- X[idx.tr,]
    y.train <- y[idx.tr]
    X.test_raw <- X[idx.te,]
    y.test <- y[idx.te]
    
    scaling.train <- Standardization(X.train_raw,X.train_raw,standardize,varSet,glm)    
    scaling.test <- Standardization(X.train_raw,X.test_raw,standardize,varSet,glm)
    X.train <- scaling.train$scaledData
    X.test <- scaling.test$scaledData
    scalingflag <- scaling.test$flag
    
    if (length(unique(y.train))<3){
      # if there is too less variation in the response, the 'cv.glmnet' will have trouble generating the lambda sequence 
      y_hat.test <- median(y.train)
    }
    else{
      cvfit <- cv.glmnet(as.matrix(X.train),as.vector(y.train),family=glm,standardize=scalingflag,nlambda=nlambda,parallel=parallel)   
      fit.lasso <- glmnet(as.matrix(X.train),as.vector(y.train),family=glm,lambda=cvfit$lambda.min,standardize=scalingflag)    
      
      y_hat.test <- predict(fit.lasso,newx=as.matrix(X.test),type="response")  
    } 
    CrimeData.eval$TSresPred[CrimeData.eval$BEAT==j&CrimeData.eval$DATEOCC==d] <- y_hat.test
  } 
}
```

```{r aggrange-result, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
# Create a STFDF with full panel (of size "number of beats * number of dates") evaluation data
CrimeData.eval$TSpred <- CrimeData.eval$TSresPred+CrimeData.eval$TStrend
CrimeData.eval$TSerr <- CrimeData.eval$INC_CNT-CrimeData.eval$TSpred
CrimeData.eval_stfdf <- ConstructSTData(CrimeData.eval,beat_template.spdf,Crd.beat,area="BEAT")

# Map results of form data frame to spatial (pixelized) representations
beat_template.pred_spdf <- beat_template.spdf
beat_template.pred_spdf@data$TSpred <- rep(NA,nrow(beat_template.pred_spdf@data))
beat_template.pred_spdf@data$TSerr <- rep(NA,nrow(beat_template.pred_spdf@data))

PredResults <- data.frame(matrix(ncol=7, nrow=nrow(grd.beat_s@coords)*length(dateSeq.eval)))
colnames(PredResults) <- c("X_COORD","Y_COORD","DATEOCC","BEAT","INC_CNT","TSpred","TSerr")
PredResults$DATEOCC <- rep(dateSeq.eval,each=nrow(grd.beat_s@coords))
PredResults$X_COORD <- rep(grd.beat_s@coords[,1],length(dateSeq.eval))
PredResults$Y_COORD <- rep(grd.beat_s@coords[,2],length(dateSeq.eval))

jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

for (i in 1:length(dateSeq.eval)){
  d <- dateSeq.eval[i]
  Pred.df <- as.data.frame(CrimeData.eval_stfdf[,d])
  Pred.df$DATEOCC <- rep(d,nrow(Pred.df))
  
  beatPred.spdf <- beat_template.pred_spdf
  for (j in beatList){
    Pred.beat_sub <- subset(Pred.df,BEAT==j)
    
    beatPred.spdf@data$INC_CNT[beatPred.spdf@data$BEAT_NUMBE==j] <- Pred.beat_sub$INC_CNT
    beatPred.spdf@data$TSpred[beatPred.spdf@data$BEAT_NUMBE==j] <- Pred.beat_sub$TSpred
    beatPred.spdf@data$TSerr[beatPred.spdf@data$BEAT_NUMBE==j] <- Pred.beat_sub$TSerr
  } 
    
  polysample <- over(grd.beat_s,beatPred.spdf)
  
  polysample <- subset(cbind(polysample, grd.beat_s@coords),select=-c(OBJECTID,DISTRICT))
  names(polysample)[names(polysample)=="BEAT_NUMBE"] <- "BEAT"

  PredResults.sub <- subset(PredResults, DATEOCC==d,select=c("X_COORD","Y_COORD","DATEOCC"))
  PredResults.sub <- merge(PredResults.sub,polysample,by=c("X_COORD","Y_COORD"),all=TRUE)
  PredResults[PredResults$DATEOCC==d,] <- PredResults.sub
}

PredResults$BEAT <- factor(PredResults$BEAT)
levels(PredResults$BEAT) <- levels(CrimeData.eval$BEAT)

grdInBeat <- over(grd.beat_s,beat_template.pred_spdf)
grdInBeat <- subset(cbind(grdInBeat, grd.beat_s@coords),select=-c(OBJECTID))
names(grdInBeat)[names(grdInBeat)=="BEAT_NUMBE"] <- "BEAT"
grdInBeat <- subset(grdInBeat,select=c("BEAT","X_COORD","Y_COORD"))
NumGrdinBeat <- as.data.frame(table(grdInBeat$BEAT))
names(NumGrdinBeat) <- c("BEAT","NumGrd")

for (i in 1:nrow(NumGrdinBeat)){
  idx <- PredResults$BEAT==NumGrdinBeat$BEAT[i]
  PredResults$INC_CNT[idx] <- PredResults$INC_CNT[idx]/NumGrdinBeat$NumGrd[i]
  PredResults$TSpred[idx] <- PredResults$TSpred[idx]/NumGrdinBeat$NumGrd[i]
  PredResults$TSerr[idx] <- PredResults$TSerr[idx]/NumGrdinBeat$NumGrd[i]
}
```

Here shows an example of time series predictions' and residuals' distribution (last evaluation example).
```{r visualize-TS-block-result, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=8, fig.height=5, cache=TRUE}
library(lattice)
# Plot time series predictions and the corresponding residual spatial distribution (only show the last evaluation example)
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))
f1 <- spplot(beatPred.spdf, zcol="TSpred", col.regions=jet.colors(256),colorkey=list(width=0.5),
             main=list("Predicted beat level crime count",cex=0.75))
f2 <- spplot(beatPred.spdf, zcol="TSerr", col.regions=jet.colors(256),colorkey=list(width=0.5),
             main=list("Residual",cex=0.75))
print(f1, position=c(0, 0, 1/2, 1), more=TRUE)
print(f2, position=c(1/2, 0, 1, 1))
```

```{r visualize-TS-pixel-result, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=8, fig.height=8, cache=TRUE, eval=FALSE}
# Here is the visualization of prediction results if we uniformly ditribute the beat count prediction over the pixels in the corresponding beat region.
## Visualize prediction results (last example)
d <- dateSeq.eval[length(dateSeq.eval)]
# Superimpose the acutal observations
CrimeActualPts <- subset(CrimeData,DATEOCC==d,select=c("DATEOCC","X_COORD","Y_COORD","INC_CNT"))

library(latticeExtra)
f1 <- levelplot(TSpred~X_COORD+Y_COORD, data=subset(PredResults,DATEOCC=d),col.regions=jet.colors(256),
                colorkey=list(width=0.75),xlab="X Coordinate",ylab="Y Coordinate",as.table=TRUE,
                main=list("Prediction and Actual Incident Locations",cex=0.75))
f2 <- xyplot(Y_COORD~X_COORD, data=CrimeActualPts, pch=16,col="red",cex=0.3,colorkey=list(width=0.75))
print(f1+as.layer(f2))
```

The evaluation is done through sensitivity(TPR)-like comparison between prediction model,long-term density and short-term density. To illustrate the idea, we demonstrate an example below the *sensitivity* plots: first selecting 10% highest pixels (threshold = 0.9 quantile of image histogram) then count how many actual crime incidents happened in these regions. And we do in this fashion for different threshold quantiles to get the *sensitivity* plot.

```{r evaluation, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
# Evalutation
# percentage of points in hot regions: raster to polygons 
# (better than contour method: having closed polygons when some sides hit boundaries)
# Sensitivity(recall)-like comparison between prediction model,long-term density and short-term density
library(igraph)
library(KernSmooth)
source("EvaluationFunction.R")

r <- raster(ncol=grd.beat_s@grid@cells.dim[1],nrow=grd.beat_s@grid@cells.dim[2],
            xmn=grd.beat_s@bbox[1,1],xmx=grd.beat_s@bbox[1,2],ymn=grd.beat_s@bbox[2,1],ymx=grd.beat_s@bbox[2,2])
period.long <- 365
period.short <- 7
probset <- seq(0,1,length.out=21)
TPR.pred <- matrix(NA,nrow=length(dateSeq.eval),ncol=length(probset))
TPR.long <- matrix(NA,nrow=length(dateSeq.eval),ncol=length(probset))
TPR.short <- matrix(NA,nrow=length(dateSeq.eval),ncol=length(probset))
bw <- grd.beat_s@grid@cellsize

CrimeActualPts <- subset(CrimeData,DATEOCC %in% dateSeq.eval,select=c("DATEOCC","X_COORD","Y_COORD","INC_CNT"))

for (i in 1:length(dateSeq.eval)){
  d <- dateSeq.eval[i]
  
  PredResults.sub <- subset(PredResults,DATEOCC==d)
  PredResults.subRaster <- rasterize(PredResults.sub[,c("X_COORD","Y_COORD")], r, 
                                     PredResults.sub$TSpred, fun=sum)
  
  CrimeHistPts.long <- subset(CrimeData,DATEOCC>=d-period.long & DATEOCC<=d-1,select=c("X_COORD","Y_COORD","INC_CNT"))
  CrimeHistPts.short <- subset(CrimeData,DATEOCC>=d-period.short & DATEOCC<=d-1,select=c("X_COORD","Y_COORD","INC_CNT"))
  
  KDE.long <- ConstrainedKDE(CrimeHistPts.long,grd.beat_s,beat_template.spdf,bandwidth=bw,raster=r)
  KDE.long_df_inPoly <- KDE.long$KDE.df
  KDE.long_df_inPolyRaster <- KDE.long$KDE.raster
  
  KDE.short <- ConstrainedKDE(CrimeHistPts.short,grd.beat_s,beat_template.spdf,bandwidth=bw,raster=r)
  KDE.short_df_inPoly <- KDE.short$KDE.df
  KDE.short_df_inPolyRaster <- KDE.short$KDE.raster
  
  CrimeActualPts.sub <- subset(CrimeActualPts,DATEOCC==d,select=c("X_COORD","Y_COORD","INC_CNT"))
  coordinates(CrimeActualPts.sub) <- c("X_COORD", "Y_COORD") # promote to SpatialPointsDataFrame
  proj4string(CrimeActualPts.sub) <- proj4string(beat_template.spdf)
  
  for (p in 1:length(probset)){ 
    Hit.pred <- HitRate(PredResults.sub$TSpred,PredResults.subRaster,probset[p],CrimeActualPts.sub)  
    Hit.long<- HitRate(KDE.long_df_inPoly$VALUE,KDE.long_df_inPolyRaster,probset[p],CrimeActualPts.sub)
    Hit.short <- HitRate(KDE.short_df_inPoly$VALUE,KDE.short_df_inPolyRaster,probset[p],CrimeActualPts.sub)  
    TPR.pred[i,p] <- Hit.pred$HitRate
    TPR.long[i,p] <- Hit.long$HitRate
    TPR.short[i,p] <- Hit.short$HitRate
  }   
}
```

```{r TPR-evaluation, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=8, fig.height=8, cache=TRUE}
par.default <- par()
# The average TPR over all evalutation examples
avgTPR.pred <- colMeans(TPR.pred)
avgTPR.long <- colMeans(TPR.long)
avgTPR.short <- colMeans(TPR.short)
par <- par.default
par(mfrow=c(1,1),pty="s")
plot(100*(1-probset),100*avgTPR.pred,type='b',col='red',cex=1,pch=16,lty="solid",cex.main=0.75,
     xlab="Percentage of the highest pixel values (%)",ylab="Hit rate (%)",main="Average sensitivity over all test examples")
lines(100*(1-probset),100*avgTPR.long,type='b',col='green',cex=1,pch=15,lty="dotted")
lines(100*(1-probset),100*avgTPR.short,type='b',col='blue',cex=1,pch=17,lty="dashed")
legend("bottom",legend=c("prediction model","long-term density","short-term density"),
       col=c("red","green","blue"),pch=c(16,15,17),lty=c("solid","dotted","dashed"),inset = c(0,0),xpd=TRUE)
```

```{r evaluation-demo, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=6, fig.height=6, cache=TRUE}
# Display one example
prob <- 0.9
Hit.pred <- HitRate(PredResults.sub$TSpred,PredResults.subRaster,prob,CrimeActualPts.sub)  
Hit.long<- HitRate(KDE.long_df_inPoly$VALUE,KDE.long_df_inPolyRaster,prob,CrimeActualPts.sub)
Hit.short <- HitRate(KDE.short_df_inPoly$VALUE,KDE.short_df_inPolyRaster,prob,CrimeActualPts.sub)  

par <- par.default
plot(PredResults.subRaster,col=jet.colors(256), main="Time series prediction",
     panel.first=grid(grd.beat_s@grid@cells.dim[2], grd.beat_s@grid@cells.dim[1],col="lightgray", lty="dotted"))
plot(Hit.pred$inPoly_poly, border="red", lwd=1.1, add=TRUE)
plot(CrimeActualPts.sub, pch=16,col="red",cex=0.5,add=TRUE)

plot(KDE.long_df_inPolyRaster,col=jet.colors(256), main="Long-term density prediction",
     panel.first=grid(grd.beat_s@grid@cells.dim[2], grd.beat_s@grid@cells.dim[1],col="lightgray", lty="dotted"))
plot(Hit.long$inPoly_poly, border="red", lwd=1.1, add=TRUE)
plot(CrimeActualPts.sub, pch=16,col="red",cex=0.5,add=TRUE)

plot(KDE.short_df_inPolyRaster,col=jet.colors(256), main="Short-term density prediction",
     panel.first=grid(grd.beat_s@grid@cells.dim[2], grd.beat_s@grid@cells.dim[1],col="lightgray", lty="dotted"))
plot(Hit.short$inPoly_poly, border="red", lwd=1.1, add=TRUE)
plot(CrimeActualPts.sub, pch=16,col="red",cex=0.5,add=TRUE)
```