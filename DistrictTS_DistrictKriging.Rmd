---
title: "DistrictTS_DistrictKriging"
date: "August 26, 2015"
output: html_document
---

```{r load-crimedata,echo=FALSE,message=FALSE,cache=TRUE}
setwd("/Users/xiaomuliu/CrimeProject/SpatioTemporalModeling/ExploratoryAnalysis/CrimeDataSTAnalysis2/")
source("importCrimeData.R")
filePath <- "/Users/xiaomuliu/CrimeProject/SpatioTemporalModeling/ExploratoryAnalysis/DataPortal/"
fileName <- "VIOLENTCRIME_01_14.csv"
CrimeData <- importCrimeData(filePath,fileName)
row.names(CrimeData) <- NULL
```

```{r load-shapefile,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
library(rgdal)
shapefilePath.new <- "/Users/xiaomuliu/CrimeProject/SpatioTemporalModeling/CPDShapeFiles/new/"
beat_new.rg <- readOGR(paste0(shapefilePath.new,"cpd_beats"), "cpd_beats")
district_new.rg <- readOGR(paste0(shapefilePath.new, "cpd_districts"),"cpd_districts")
# centroids 
Crd.beat <- coordinates(beat_new.rg)
Crd.district <- coordinates(district_new.rg)
```

The beat and district numbers in the data were re-assigned by finding in which new beat/district polygon the point falls and then label that beat/district number. Therefore all violent crime beat and district records have a unified reference which is the new CPD beat/district map.

```{r rearrange-data,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
## Match old and new beat 
# Matching the old beat records and the new one by finding which new beat polygon the point falls in
# and then re-assign that beat number to that crime record. 
# Therefore all crime beat records have a unified reference which is the new beat map.
source("DataPolyMatching.R")
Match1 <- DataMatching2(CrimeData,beat_new.rg,area="BEAT")
CrimeData <- Match1$CrimeData
Match2 <- DataMatching2(CrimeData,district_new.rg,area="DISTRICT")
CrimeData <- Match2$CrimeData

## Aggregated by "beat" and add 'holiday' attribute
source("HolidayChart.R")
CrimeData.beat_day <- aggregate(INC_CNT~BEAT+DISTRICT+DATEOCC+YEAR+MONTH+DOW,data=CrimeData, FUN=sum, na.rm=TRUE)
CrimeData.beat_day <- CrimeData.beat_day[order(CrimeData.beat_day$DATEOCC),]
CrimeData.beat_day$DOW <- factor(CrimeData.beat_day$DOW, levels=c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"))
CrimeData.beat_day$HOLIDAY <- sapply(CrimeData.beat_day$DATEOCC,FUN=holidays)
CrimeData.beat_day$HOLIDAY <- factor(CrimeData.beat_day$HOLIDAY)

CrimeData$HOLIDAY <- sapply(CrimeData$DATEOCC,FUN=holidays)
CrimeData$HOLIDAY <- factor(CrimeData$HOLIDAY)
```

```{r construct-panel-data,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
## Create a full panel (of size "number of beats * number of dates") data frame and an corresponding STFDF
beat_template.spdf <- beat_new.rg
# remove some useless/redundant attributes
beat_template.spdf@data$SECTOR <- NULL
beat_template.spdf@data$BEAT <- NULL
beat_template.spdf@data$BEAT_NUM <- NULL
# add an attribute INC_CNT
beat_template.spdf@data$INC_CNT <- rep(NA,nrow(beat_template.spdf@data))

source("ConstructSTData.R")
STdata.beat <- ConstructArealSTData(CrimeData.beat_day,beat_template.spdf,Crd.beat,area="BEAT") 
CrimeData_beat_day.stfdf <-STdata.beat$CrimeData.stfdf 
CrimeData.beat_day <- STdata.beat$CrimeData 

# Add corresponding district numbers for each beat
inDistrict <- aggregate(.~BEAT_NUMBE,data=beat_template.spdf@data[,c("DISTRICT","BEAT_NUMBE")],FUN=function(x){x[1]})
names(inDistrict)[names(inDistrict)=="BEAT_NUMBE"] <- "BEAT"
inDistrict$DISTRICT <- factor(inDistrict$DISTRICT)
levels(inDistrict$DISTRICT) <- levels(CrimeData$DISTRICT)

CrimeData_beat_day.stfdf@data$DISTRICT <- rep(NA,nrow(CrimeData_beat_day.stfdf@data))
for (i in 1:nrow(inDistrict)){
  CrimeData.beat_day$DISTRICT[CrimeData.beat_day$BEAT==inDistrict$BEAT[i]] <- inDistrict$DISTRICT[i]
  CrimeData_beat_day.stfdf@data$DISTRICT[CrimeData_beat_day.stfdf@data$BEAT==inDistrict$BEAT[i]] <- inDistrict$DISTRICT[i]
}
```

```{r load-weather-data,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
## Load weather data
source("WeatherDataFunctions.R")
WeatherFilePath <- "/Users/xiaomuliu/CrimeProject/SpatioTemporalModeling/ExploratoryAnalysis/WeatherData/"
startDate="01/01/2001"
endDate="12/31/2014"
filename.daily <- paste(WeatherFilePath,'WeatherData_Daily_',as.character(as.Date(startDate, "%m/%d/%Y")),
                        '_',as.character(as.Date(endDate, "%m/%d/%Y")),'.csv',sep='')
WeatherData.daily <- read.csv(filename.daily)
WeatherData.daily$Date <- as.Date(WeatherData.daily$Date)
WeatherData.daily_diff <- DailyWeatherDiff(WeatherData.daily)
```

```{r fit-district-trend,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
## Fit a temporal model which is specified below for every district
require(MASS)
require(glmnet)
require(dummies)
require(spacetime)
require(doMC)
registerDoMC(cores=4)

beatList <- sort(unique(CrimeData.beat_day$BEAT))
districtList <- sort(unique(CrimeData.beat_day$DISTRICT))
NumBeat <- length(beatList)
NumDistrict <- length(districtList)
district_NumBeat <- aggregate(BEAT~DISTRICT,data=CrimeData.beat_day,FUN=function(x){length(unique(x))})
names(district_NumBeat) <- c("DISTRICT","NumBeat")

# First 'trendLen' instances work as buffering data
trendLen <- 730
CrimeData.buffer <- CrimeData.beat_day[1:NumBeat*trendLen,]
CrimeData.nonbuffer <- CrimeData.beat_day[(NumBeat*trendLen+1):nrow(CrimeData.beat_day),]
CrimeData.nonbuffer$TStrend <- rep(NA,nrow(CrimeData.nonbuffer))
CrimeData.nonbuffer$TSdetrendRes <- rep(NA,nrow(CrimeData.nonbuffer))
WeatherData.nonbuffer <- WeatherData.daily[(trendLen+1):nrow(WeatherData.daily),]
WeatherDataDiff.nonbuffer <- WeatherData.daily_diff[(trendLen-1):nrow(WeatherData.daily_diff),] 

## Predict trend and get residuals for each district (beat)
CrimeData.district_day <- aggregate(INC_CNT~DISTRICT+DATEOCC+YEAR+MONTH+DOW+HOLIDAY,data=CrimeData.beat_day, FUN=sum, na.rm=TRUE)
CrimeData.district_day <- CrimeData.district_day[order(CrimeData.district_day$DATEOCC),]
CrimeData.district_day$DOW <- factor(CrimeData.district_day$DOW, levels=c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"))

source("TimeSeriesFunction.R")
for (i in districtList){
  CrimeData.district <- subset(CrimeData.district_day,DISTRICT==i,select=c("DATEOCC","DOW","MONTH","HOLIDAY","INC_CNT"))
  
  # Smooth out holiday cases:
  CrimeData.district$INC_CNT_s <- SmoothHoliday(CrimeData.district)
  
  Trend <- PredictTrend(CrimeData.district,trendLen,nlfit="IRLS") 
  # District trend values are divided by the number of beat in corresponding district to get evenly distributed beat trend estimates
  idx <- CrimeData.nonbuffer$DISTRICT==i
  nbeat <- district_NumBeat$NumBeat[district_NumBeat$DISTRICT==i]
  CrimeData.nonbuffer$TStrend[idx] <- rep(Trend, each=nbeat) / nbeat
  CrimeData.nonbuffer$TSdetrendRes[idx] <- CrimeData.nonbuffer$INC_CNT[idx]-CrimeData.nonbuffer$TStrend[idx]  
}
```

The evaluation date starts from 2014-08-01 and ends on 2014-08-04. The time series training uses 12-year data before the corresponding testing date.   
```{r kriging-setting,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
library(gstat)
library(xts)
library(raster)

# Evaluation periods
startDate.eval = as.Date("2014-08-01")
endDate.eval <- as.Date("2014-08-04")
dateSeq.eval <- seq.Date(startDate.eval,endDate.eval,by=1)

CrimeData.eval <- subset(CrimeData.nonbuffer,DATEOCC %in% dateSeq.eval)
CrimeData.eval$TSresPred <- rep(NA,nrow(CrimeData.eval))

# Input arguments for time series regression
glm <- "gaussian"
varSet <- c("DOW","weather","weatherdiff")
standardize <- "minmax"
Windowing <- FALSE
nlambda <- 20
Ntrain <- 365*12
winSize <- 90
winNum <- 12
parallel <- TRUE

# spatial separation distance up to which point pairs are included in semivariance estimates
# the length of the diagonal of the box spanning the data is divided by a certain number
cutoff <- 15000
width <- 500
vgm.prodsum <- vgmST("productSum",space=vgm(psill=0.5,"Sph",range=5000, nugget=0.5),
                     time=vgm(psill=0.07,"Sph",range=1,nugget=0.5), sill=1, nugget=0.5)
Nvario <- 365*2

# The spatial interpolation is done over a 'interpx*interpy' regular grid within the city border.
# spatial interpolation grid
ncell.x <- 120
ncell.y <- 160
X_range <- beat_new.rg@bbox[1,]
Y_range <- beat_new.rg@bbox[2,]
grd.full <- expand.grid(list(X_COORD=seq(X_range[1],X_range[2],length.out=ncell.x),
                             Y_COORD=seq(Y_range[1],Y_range[2],length.out=ncell.y)))
coordinates(grd.full) = ~X_COORD+Y_COORD # convert to SpatialPoints
proj4string(grd.full) <- proj4string(beat_new.rg)

grdInCity <- over(grd.full,as(beat_new.rg,"SpatialPolygons"))

grd.beat_s <- grd.full[!is.na(grdInCity)]
grd.beat_s <- SpatialPixels(grd.beat_s)

krigeST.df <- data.frame(X_COORD=rep(grd.beat_s@coords[,1],length(dateSeq.eval)),
                         Y_COORD=rep(grd.beat_s@coords[,2],length(dateSeq.eval)),
                         DATEOCC=rep(dateSeq.eval,each=nrow(grd.beat_s@coords)),
                         krigePred=rep(NA,nrow(grd.beat_s@coords)*length(dateSeq.eval)))
```

The time series models were applied to each district. Then uniformly allocate the residuals to each beat, i.e. the temporal model residual of each beat is assumed be the district residual divided by the number of beats in that district.

```{r districtTS-districtKriging,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
## Predict detrending residuals for each beat (by averaging district residuals)
# and then do Kriging based on beat-level spatio-temporal (local) variograms of temporal model errors

for (i in 1:length(dateSeq.eval)){
  # pinpoint the training time range
  d <- dateSeq.eval[i]
  startDate.train <- d-Ntrain
  endDate.train <- d-1
  dateSeq.train <- seq.Date(startDate.train,endDate.train,by=1)
  
  CrimeData.test <- subset(CrimeData.nonbuffer,DATEOCC==d)
  WeatherData.test <- subset(WeatherData.nonbuffer,Date==d)
  WeatherDataDiff.test <- subset(WeatherDataDiff.nonbuffer,Date==d)
  
  if (Windowing){
    dateWindow <- HistDateWindows(dateSeq.train,d,windowSize=winSize,windowNum=winNum,interval=365.25,dir="backward")
    CrimeData.train <- subset(CrimeData.nonbuffer,DATEOCC %in% dateWindow$histDates)
    WeatherData.train <- subset(WeatherData.nonbuffer,Date %in% dateWindow$histDates)
    WeatherDataDiff.train <- subset(WeatherDataDiff.nonbuffer,Date %in% dateWindow$histDates)
  }
  else{
    # use all training data: 
    CrimeData.train <- subset(CrimeData.nonbuffer,DATEOCC %in% dateSeq.train)
    WeatherData.train <- subset(WeatherData.nonbuffer,Date %in% dateSeq.train)
    WeatherDataDiff.train <- subset(WeatherDataDiff.nonbuffer,Date %in% dateSeq.train)
  }
  
  CrimeData.train$TSresPred <- rep(NA,nrow(CrimeData.train))
  
  for (j in districtList){
    # district 31 has too few samples
    if (j=="031"){
      CrimeData.eval$TSresPred[CrimeData.eval$DISTRICT==j&CrimeData.eval$DATEOCC==d] <- 0
      CrimeData.train$TSresPred[CrimeData.eval$DISTRICT==j] <- 0
      next
    }
    
    #Combine training data of all variables     
    CrimeData.train_district <- aggregate(cbind(INC_CNT,TStrend,TSdetrendRes)~DISTRICT+DATEOCC+MONTH+DOW, 
                                                data=CrimeData.train, FUN=sum, na.rm=TRUE)
    CrimeData.train_district <- CrimeData.train_district[order(CrimeData.train_district$DATEOCC),]
    CrimeData.train_district$DOW <- factor(CrimeData.train_district$DOW, levels=c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"))
    
    CrimeData.test_district <- aggregate(cbind(INC_CNT,TStrend,TSdetrendRes)~DISTRICT+DATEOCC+MONTH+DOW, 
                                          data=CrimeData.test, FUN=sum, na.rm=TRUE)
    CrimeData.test_district <- CrimeData.test_district[order(CrimeData.test_district$DATEOCC),]
    CrimeData.test_district$DOW <- factor(CrimeData.test_district$DOW, levels=c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"))
    
    CrimeData.train_district <- subset(CrimeData.train_district,DISTRICT==j,
                                       select=c("DATEOCC","DOW","MONTH","INC_CNT","TStrend","TSdetrendRes"))
    CrimeData.test_district <- subset(CrimeData.test_district,DISTRICT==j,
                                      select=c("DATEOCC","DOW","MONTH","INC_CNT","TStrend","TSdetrendRes"))
    
    selectData.train <- VariableSet(varSet,CrimeData.train_district,WeatherData.train,WeatherDataDiff.train,glm)
    selectData.test <- VariableSet(varSet,CrimeData.test_district,WeatherData.test,WeatherDataDiff.test,glm)
    
    X.train_raw <- selectData.train$X
    y.train <- selectData.train$y   
    X.test_raw <- selectData.test$X
    y.test <- selectData.test$y
    
    scaling.train <- Standardization(X.train_raw,X.train_raw,standardize,varSet,glm)    
    scaling.test <- Standardization(X.train_raw,X.test_raw,standardize,varSet,glm)
    X.train <- scaling.train$scaledData
    X.test <- scaling.test$scaledData
    scalingflag <- scaling.test$flag
    
    if (length(unique(y.train))<3){
      # if there is too less variation in the response, the 'cv.glmnet' will have trouble generating the lambda sequence 
      y_hat.test <- median(y.train)
      y_hat.train <- rep(median(y.train),length(y.train))
    }
    else{
      cvfit <- cv.glmnet(as.matrix(X.train),as.vector(y.train),family=glm,standardize=scalingflag,nlambda=nlambda,parallel=parallel)   
      fit.lasso <- glmnet(as.matrix(X.train),as.vector(y.train),family=glm,lambda=cvfit$lambda.min,standardize=scalingflag)    
      
      y_hat.test <- predict(fit.lasso,newx=as.matrix(X.test),type="response")
      y_hat.train <- predict(fit.lasso,newx=as.matrix(X.train),type="response")     
    } 
    
    idx.eval <- CrimeData.eval$DISTRICT==j&CrimeData.eval$DATEOCC==d
    idx.train <- CrimeData.train$DISTRICT==j
    nbeat <- district_NumBeat$NumBeat[district_NumBeat$DISTRICT==j]
    CrimeData.eval$TSresPred[idx.eval] <- rep(y_hat.test, each=nbeat) / nbeat
    CrimeData.train$TSresPred[idx.train] <- rep(y_hat.train, each=nbeat) / nbeat
  }
  
  CrimeData.train <- within(CrimeData.train, TSpred <- TSresPred+TStrend)
  CrimeData.train <- within(CrimeData.train, TSerr <- INC_CNT-TSpred)
    
  # temporal grid 
  grd.beat_t <- xts(1:1,order.by=seq(d,d,by=1))
  
  # Loop over each district to estimate local variograms and do Kriging prediction
  # use only *Nvario* samples to estimate variograms
  if (nrow(CrimeData.train)/NumBeat > Nvario){
    CrimeData.train <- CrimeData.train[(nrow(CrimeData.train)-Nvario*NumBeat+1):nrow(CrimeData.train),]
  }
  
  # create a global training STFDF then subset it locally in the loop
  CrimeData.train_stfdf <- ConstructSTData(CrimeData.train,beat_template.spdf,Crd.beat,area="BEAT")
  
  for (k in districtList){
    if (k=="031"){
      grdInDistrict <- over(as(grd.beat_s,"SpatialPoints"),
                            as(district_new.rg[district_new.rg$DISTRICT=="031",],"SpatialPolygons"))
      grd.local_beat_s <- grd.beat_s[!is.na(grdInDistrict)]
      for (m in 1:nrow(grd.local_beat_s@coords)){
        matchIdx <- with(krigeST.df, DATEOCC==d & X_COORD==grd.local_beat_s@coords[m,1] & Y_COORD==grd.local_beat_s@coords[m,2])
        krigeST.df$krigePred[matchIdx] <- 0
      }
      next
    }
    CrimeData.train_local <- subset(CrimeData.train,DISTRICT==k)

    CrimeData.train_local_stfdf <- CrimeData.train_stfdf[CrimeData.train_stfdf$DISTRICT==k, ,
                                                         names(CrimeData.train_stfdf@data),drop=FALSE] 
    stVgm.local_beat <- variogramST(TSerr~1,CrimeData.train_local_stfdf[, ,"TSerr"],cutoff=cutoff,
                                    width=width,tlags=0:14,assumeRegular=TRUE,progress=FALSE,na.omit=TRUE)
    
    # extractPar(vgm.prodsum)
    # parameter order: space sill, space range, time sill, time range, sill, nugget 
    vgm.prodsum_fit <- fit.StVariogram(stVgm.local_beat,vgm.prodsum,fit.method=6,method="L-BFGS-B",
                                       lower=c(0.01,1000,0.01,1,0.1,0.01),upper=c(10,30000,10,14,10,5))

    
    # local spatial grid (inside a certain distirct)
    grdInDistrict <- over(as(grd.beat_s,"SpatialPoints"),
                          as(district_new.rg[district_new.rg$DISTRICT==k,],"SpatialPolygons"))
    
    grd.local_beat_s <- grd.beat_s[!is.na(grdInDistrict)]
    # grd.local_beat_s <- SpatialPixels(grd.local_beat_s)
    
    # spatio-temporal grid
    grd.local_beat_st <- STF(grd.local_beat_s,grd.beat_t,endTime=as.POSIXct(d+1))
    
    # Kriging
    attr(vgm.prodsum_fit, "temporal unit") <- "days"

    # Use only recent 14 days for prediction  
    predST.local_beat <- krigeST(TSerr~1, data=CrimeData.train_local_stfdf[,(length(CrimeData.train_local_stfdf@time)-13)
                                                                           :length(CrimeData.train_local_stfdf@time),"TSerr"], 
                                 newdata=grd.local_beat_st, modelList=vgm.prodsum_fit, computeVar=F, progress=F)

    predST.df <- as.data.frame(predST.local_beat)
    predST.df$endTime <- NULL
    predST.df$sp.ID <- NULL
    predST.df$timedata <- NULL
    names(predST.df)[1:ncol(predST.df)] <- c("X_COORD","Y_COORD","DATEOCC","krigePred")
    
    for (m in 1:nrow(predST.df)){
      matchIdx <- with(krigeST.df, DATEOCC==d & X_COORD==predST.df$X_COORD[m] & Y_COORD==predST.df$Y_COORD[m])
      krigeST.df[matchIdx,] <- predST.df[m,]
    }
  } 
}
```

Variogram models were estimated from recent two-year beat-level residual data. For each district, we calculate an empirical variogram. And if a point on the fine regular grid falls into a district, its spatial interpolation will be done through the Kriging using this district's variogram. We use only two year data and consider the time intervals up to 14 days to relieve computation burden. In our experiment, we choose the product-sum model with the spherical model for both temporal and spatial terms. One variogram example and its fitting is shown below.
```{r vgm-example, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=6, fig.height=4.5, cache=TRUE}
# show the variogram plot of the last evaluation example
f <- plot(stVgm.local_beat,vgm.prodsum_fit, all=T, wireframe=T, zlab=NULL, xlab=list("distance", rot=30), 
          ylab=list("time lag", rot=-35),scales=list(arrows=F,z=list(distance=5)), colorkey=list(width=0.75))
print(f)
```

```{r aggrange-result, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
# Create a STFDF with full panel (of size "number of beats * number of dates") evaluation data
CrimeData.eval <- within(CrimeData.eval, TSpred <- TSresPred+TStrend)
CrimeData.eval <- within(CrimeData.eval, TSerr <- INC_CNT-TSpred)

CrimeData.eval_stfdf <- ConstructSTData(CrimeData.eval,beat_template.spdf,Crd.beat,area="BEAT")

# Map results of form data frame to spatial (pixelized) representations
beat_template.pred_spdf <- beat_template.spdf
beat_template.pred_spdf@data$TSpred <- rep(NA,nrow(beat_template.pred_spdf@data))
beat_template.pred_spdf@data$TSerr <- rep(NA,nrow(beat_template.pred_spdf@data))
beat_template.pred_spdf@data$krigePred <- rep(NA,nrow(beat_template.pred_spdf@data))

PredResults <- data.frame(matrix(ncol=10, nrow=nrow(krigeST.df)))
colnames(PredResults) <- c("X_COORD","Y_COORD","DATEOCC","DISTRICT","BEAT","INC_CNT","TSpred","TSerr","krigePred","overlayPred")
PredResults$DATEOCC <- krigeST.df$DATEOCC

for (i in 1:length(dateSeq.eval)){
  d <- dateSeq.eval[i]
  Pred.df <- as.data.frame(CrimeData.eval_stfdf[,d])
  Pred.df$DATEOCC <- rep(d,nrow(Pred.df))
  
  beatPred.spdf <- beat_template.pred_spdf
  for (j in beatList){
    Pred.beat_sub <- subset(Pred.df,BEAT==j)
    
    beatPred.spdf@data$INC_CNT[beatPred.spdf@data$BEAT_NUMBE==j] <- Pred.beat_sub$INC_CNT
    beatPred.spdf@data$TSpred[beatPred.spdf@data$BEAT_NUMBE==j] <- Pred.beat_sub$TSpred
    beatPred.spdf@data$TSerr[beatPred.spdf@data$BEAT_NUMBE==j] <- Pred.beat_sub$TSerr
  } 
    
  polysample <- over(grd.beat_s,beatPred.spdf)
  
  polysample <- subset(cbind(polysample, grd.beat_s@coords),select=-c(OBJECTID))
  names(polysample)[names(polysample)=="BEAT_NUMBE"] <- "BEAT"
  
  PredResults.sub <- subset(krigeST.df, DATEOCC==d)
  PredResults.sub <- merge(PredResults.sub,polysample,by=c("X_COORD","Y_COORD"),all=TRUE)
  PredResults.sub$krigePred.y <- NULL                                
  names(PredResults.sub)[names(PredResults.sub)=="krigePred.x"] <- "krigePred"
  PredResults.sub$overlayPred <- PredResults.sub$TSpred + PredResults.sub$krigePred
  
  PredResults[PredResults$DATEOCC==d,names(PredResults.sub)] <- PredResults.sub
}
```
Here shows an example of time series predictions' and residuals' distribution (last evaluation example).

```{r visualize-TS-result, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=6, fig.height=4.5, cache=TRUE}
# Plot time series predictions and the corresponding residual spatial distribution (only show the last evaluation example)
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))
f1 <- spplot(beatPred.spdf, zcol="TSpred", col.regions=jet.colors(256),colorkey=list(width=0.5),
             main=list("Predicted beat level crime count",cex=0.75))
f2 <- spplot(beatPred.spdf, zcol="TSerr", col.regions=jet.colors(256),colorkey=list(width=0.5),
             main=list("Residual",cex=0.75))
print(f1, position=c(0, 0, 1/2, 1), more=TRUE)
print(f2, position=c(1/2, 0, 1, 1))
```
Here is the visualization of prediction results.
```{r visualize-Krige-result, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=8, fig.height=8, cache=TRUE}
## Visualize prediction results
# Superimpose the acutal observations
CrimeActualPts <- subset(CrimeData,DATEOCC %in% dateSeq.eval,select=c("DATEOCC","X_COORD","Y_COORD","INC_CNT"))

library(latticeExtra)
f1 <- levelplot(overlayPred~X_COORD+Y_COORD|DATEOCC, data=PredResults,col.regions=jet.colors(256),
                colorkey=list(width=0.75),xlab="X Coordinate",ylab="Y Coordinate",as.table=TRUE,
                main=list("Prediction and Actual Incident Locations",cex=0.75))
f2 <- xyplot(Y_COORD~X_COORD|DATEOCC, data=CrimeActualPts, pch=16,col="red",cex=0.3,colorkey=list(width=0.75))
print(f1+as.layer(f2))
```
The evaluation is done through sensitivity(TPR)-like comparison between prediction model,long-term density and short-term density. To illustrate the idea, we demonstrate an example below the *sensitivity* plots: first selecting 10% highest pixels (threshold = 0.9 quantile of image histogram) then count how many actual crime incidents happened in these regions. And we do in this fashion for different threshold quantiles to get the *sensitivity* plot.
```{r evaluation, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
# Evalutation
# percentage of points in hot regions: raster to polygons 
# (better than contour method: having closed polygons when some sides hit boundaries)
# Sensitivity(recall)-like comparison between prediction model,long-term density and short-term density
library(igraph)
library(KernSmooth)
source("EvaluationFunction.R")

r <- raster(ncol=grd.beat_s@grid@cells.dim[1],nrow=grd.beat_s@grid@cells.dim[2],
            xmn=grd.beat_s@bbox[1,1],xmx=grd.beat_s@bbox[1,2],ymn=grd.beat_s@bbox[2,1],ymx=grd.beat_s@bbox[2,2])
period.long <- 365
period.short <- 7
probset <- seq(0,1,length.out=21)
TPR.pred <- matrix(NA,nrow=length(dateSeq.eval),ncol=length(probset))
TPR.long <- matrix(NA,nrow=length(dateSeq.eval),ncol=length(probset))
TPR.short <- matrix(NA,nrow=length(dateSeq.eval),ncol=length(probset))
bw <- 1*grd.beat_s@grid@cellsize

for (i in 1:length(dateSeq.eval)){
  d <- dateSeq.eval[i]
  
  PredResults.sub <- subset(PredResults,DATEOCC==d)
  PredResults.subRaster <- rasterize(PredResults.sub[,c("X_COORD","Y_COORD")], r, 
                                     PredResults.sub$overlayPred, fun=sum)
  
  CrimeHistPts.long <- subset(CrimeData,DATEOCC>=d-period.long & DATEOCC<=d-1,select=c("X_COORD","Y_COORD","INC_CNT"))
  CrimeHistPts.short <- subset(CrimeData,DATEOCC>=d-period.short & DATEOCC<=d-1,select=c("X_COORD","Y_COORD","INC_CNT"))
  
  KDE.long <- ConstrainedKDE(CrimeHistPts.long,grd.beat_s,beat_template.spdf,bandwidth=bw,raster=r)
  KDE.long_df_inPoly <- KDE.long$KDE.df
  KDE.long_df_inPolyRaster <- KDE.long$KDE.raster
  
  KDE.short <- ConstrainedKDE(CrimeHistPts.short,grd.beat_s,beat_template.spdf,bandwidth=bw,raster=r)
  KDE.short_df_inPoly <- KDE.short$KDE.df
  KDE.short_df_inPolyRaster <- KDE.short$KDE.raster
  
  CrimeActualPts.sub <- subset(CrimeActualPts,DATEOCC==d,select=c("X_COORD","Y_COORD","INC_CNT"))
  coordinates(CrimeActualPts.sub) <- c("X_COORD", "Y_COORD") # promote to SpatialPointsDataFrame
  proj4string(CrimeActualPts.sub) <- proj4string(beat_template.spdf)
  
  for (p in 1:length(probset)){ 
    Hit.pred <- HitRate(PredResults.sub$overlayPred,PredResults.subRaster,probset[p],CrimeActualPts.sub)  
    Hit.long<- HitRate(KDE.long_df_inPoly$VALUE,KDE.long_df_inPolyRaster,probset[p],CrimeActualPts.sub)
    Hit.short <- HitRate(KDE.short_df_inPoly$VALUE,KDE.short_df_inPolyRaster,probset[p],CrimeActualPts.sub)  
    TPR.pred[i,p] <- Hit.pred$HitRate
    TPR.long[i,p] <- Hit.long$HitRate
    TPR.short[i,p] <- Hit.short$HitRate
  }   
}
```

```{r visualize-evaluation, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=8, fig.height=8, cache=TRUE}
par.default <- par()
par(mfrow=c(2,2),mar=c(4, 4, 3, 2),oma=c(4,0,1,0),xpd=NA)
for (i in 1:length(dateSeq.eval)){
  plot(probset,TPR.pred[i,],type='b',col='red',cex=1,pch=16,lty="solid",
       xlab="Pixel quantile of hot spots",ylab="Hit rate",main=dateSeq.eval[i],cex.main=0.75)
  lines(probset,TPR.long[i,],type='b',col='green',cex=1,pch=15,lty="dotted")
  lines(probset,TPR.short[i,],type='b',col='blue',cex=1,pch=17,lty="dashed")
}
mtext("Sensitivity",side=3,cex=1,outer=TRUE)
par(fig=c(0,1,0,1), oma=c(0,0,0,0), mar=c(0,0,0,0), new=TRUE)
plot(0, 0, type="n", bty="n", xaxt="n", yaxt="n")
legend("bottom",legend=c("prediction model","long-term density","short-term density"),
       col=c("red","green","blue"),pch=c(16,15,17),lty=c("solid","dotted","dashed"),inset = c(0,0),xpd=TRUE)
```

```{r evaluation-demo, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=6, fig.height=6, cache=TRUE}
# Display one example
prob <- 0.9
Hit.pred <- HitRate(PredResults.sub$overlayPred,PredResults.subRaster,prob,CrimeActualPts.sub)  
Hit.long<- HitRate(KDE.long_df_inPoly$VALUE,KDE.long_df_inPolyRaster,prob,CrimeActualPts.sub)
Hit.short <- HitRate(KDE.short_df_inPoly$VALUE,KDE.short_df_inPolyRaster,prob,CrimeActualPts.sub)  

par <- par.default
plot(PredResults.subRaster,col=jet.colors(256), main="Kriging predition",
     panel.first=grid(grd.beat_s@grid@cells.dim[2], grd.beat_s@grid@cells.dim[1],col="lightgray", lty="dotted"))
plot(Hit.pred$inPoly_poly, border="red", lwd=1.2, add=TRUE)
plot(CrimeActualPts.sub, pch=16,col="red",cex=0.5,add=TRUE)

plot(KDE.long_df_inPolyRaster,col=jet.colors(256), main="Long-term density predition",
     panel.first=grid(grd.beat_s@grid@cells.dim[2], grd.beat_s@grid@cells.dim[1],col="lightgray", lty="dotted"))
plot(Hit.long$inPoly_poly, border="red", lwd=1.2, add=TRUE)
plot(CrimeActualPts.sub, pch=16,col="red",cex=0.5,add=TRUE)

plot(KDE.short_df_inPolyRaster,col=jet.colors(256), main="Short-term density prediction",
     panel.first=grid(grd.beat_s@grid@cells.dim[2], grd.beat_s@grid@cells.dim[1],col="lightgray", lty="dotted"))
plot(Hit.short$inPoly_poly, border="red", lwd=1.2, add=TRUE)
plot(CrimeActualPts.sub, pch=16,col="red",cex=0.5,add=TRUE)
```